# Report October 2nd 2023
### Quick note/summary: 
I have been reading papers and getting a general sense of where things are. I left off with some photogrammetry models. Again, working with photography and Reality Capture. 
I also spent some time looking into LiDAR scanners and NeRF. In general, I read a little bit about computer vision and some other tools. 
## Activities/Went through: 
  * Readings: 
      * Manula Haputhanthri; Charana Himasha; Hansi Balasooriya; Malithi Herath;
Samantha Rajapaksha. “Computer Vision Based Navigation Robot”. In:
IEEE Conference Pape (2022).
      * Ben Mildenhall. “Representing Scenes as Neural Radiance Rields for View
Synthesis”. In: ECCV (2020).
      * et al Lei He. “De-Skewing Lidar Scan for Refinement of Local Mapping.”
In: (2020).
      * et al Kyungmin Jo. “CG-NeRF: Conditional Generative Neural Radiance
Fields for 3D-aware Image Synthesis”. In: IEEE (2023).
      * Peter Hedman. “Baking Neural Radiance Fields for Real Time View Syn-
thesis”. In: (2021).
      * Don Murray Cullen Jennings. “Stereo Vision based Mapping and Naviga-
tion for Mobile Robots”. In: Proceedings of International Conference on
Robotics and Automation (1997).
      * et al Ajay Jain. “Sematically Consistent Few-Shot View Synthesis”. In:
(2021).
  * Photogrammetry: 
    * I have not worked on photogrammetric models just yet. I am waiting to read a little more on the methods to then start trying and experimenting. 
## Moving Forward: 
  * I plan to read through some documentation and information abut: LumaAI, 3D Gaussian Splatting, and I will also continue to look into older approaches like polycam,
    reality capture(and photography), and NeRF. 
  
 
  
